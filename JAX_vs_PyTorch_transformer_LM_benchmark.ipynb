{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "JAX vs PyTorch transformer LM benchmark",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuOcMJmZw1jN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/enolan/jax-torch-bench/blob/master/JAX_vs_PyTorch_transformer_LM_benchmark.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DLbS-ISEN_W"
      },
      "source": [
        "# Config is tuned for a P100, a 16GB GPU. You'll have to reduce the batch sizes to get\n",
        "# the models running if Colab gives you something smaller.\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnyCohiXCm3_"
      },
      "source": [
        "# Common setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He4JoFYEptcu"
      },
      "source": [
        "!wget http://mattmahoney.net/dc/enwik9.zip\n",
        "!unzip enwik9.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naYZSB2yqHoZ"
      },
      "source": [
        "!pip install optax flax\n",
        "!pip install -U numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKDj1z15m81t"
      },
      "source": [
        "!git clone https://github.com/enolan/jax-torch-bench.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWHnhLyWL-_i"
      },
      "source": [
        "%cd jax-torch-bench"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uLr90ovCupj"
      },
      "source": [
        "from config import ModelConfig\n",
        "\n",
        "enwik9 = \"/content/enwik9\"\n",
        "\n",
        "# This is the highest batch size PyTorch can handle, the JAX model can do 79\n",
        "cfg = ModelConfig(seq_len=256, n_layers=12, d_model=512, num_heads=8, ff_dim=3072, dropout=0.1, batch_size=63, learning_rate=1e-3)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zV7tab1Ch4z"
      },
      "source": [
        "# JAX model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfYJzTMXqpdm"
      },
      "source": [
        "from jax_model import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mms4hEafx7PR"
      },
      "source": [
        "# Set up the model\n",
        "params, model, optimizer, opt_state, sample = setup_all(cfg)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6AdAkqQim-c"
      },
      "source": [
        "# This will run the training loop indefinitely. Hit the stop button to abort.\n",
        "params, opt_state = train_loop(model, optimizer, opt_state, params, cfg, enwik9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwY1-5tehAK9"
      },
      "source": [
        "sample(params, \"'''Star Trek'''\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99j1fHUFDr_O"
      },
      "source": [
        "# PyTorch model\n",
        "\n",
        "Since JAX preallocates all GPU memory, you'll need to restart the runtime (Runtime -> Restart runtime) to try the PyTorch model. Then rerun the config setup cell before running the ones below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0iUAGmwR39M"
      },
      "source": [
        "from pytorch_model import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBa39lPzR9Wg"
      },
      "source": [
        "lm = LM(cfg).cuda()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvoKZykNR_UU"
      },
      "source": [
        "train_loop(lm, cfg, enwik9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBoNK-cISWkB"
      },
      "source": [
        "lm.sample(\"'''Star Trek'''\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
